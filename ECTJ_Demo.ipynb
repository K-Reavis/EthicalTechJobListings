{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str(tup):\n",
    "    if tup[0] == '':\n",
    "        return tup[1]\n",
    "    return tup[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_files(companies, titles, texts):\n",
    "    end_point = len(companies) \n",
    "    for i in range(0, end_point):\n",
    "        post_id = 'postings/' + str(i) + '-' + re.sub(\"[^A-Za-z]\", \"\", companies[i].strip()) + '-' + re.sub(\"[^A-Za-z]\", \"\", titles[i].strip()) + '.rtf'\n",
    "        out_file = open(post_id,'w', encoding=\"utf-8\", errors = 'ignore')\n",
    "        out_file.write(texts[i])\n",
    "        out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_indeed(companies, titles, urls):\n",
    "    text_lst = []\n",
    "    edu_lst = []\n",
    "    for url in urls:\n",
    "        education = []\n",
    "        myRequest = requests.get(url)\n",
    "        soup = str(BeautifulSoup(myRequest.text, \"html.parser\")).replace(\"\\n\", \"\")\n",
    "        paragraph_text = r'<p>(.*?)</p>'\n",
    "        list_text = r'<li>(.*?)</li>'\n",
    "        clean = re.compile('<.*?>')\n",
    "        text = \" \".join([re.sub(clean, '', get_str(x)).replace(\"amp;\", \"\") for x in re.findall(paragraph_text + \"|\" + list_text, soup)])\n",
    "        if len(re.findall(\"(?i) GED |High School\", text)) > 0:\n",
    "            education.append(\"High School\")\n",
    "        if len(re.findall(\" BS | BA | B.S. | B.A. |Bachelor\", text)) > 0:\n",
    "            education.append(\"Bachelor's\")\n",
    "        if len(re.findall(\" MS | M.S. |Master\", text)) > 0:\n",
    "            education.append(\"Master's\")\n",
    "        if len(re.findall(\"PhD | Ph.D. |Doctorate\", text)) > 0:\n",
    "            education.append(\"PhD\")\n",
    "        text_lst.append(text)\n",
    "        edu_lst.append(\" \".join(education))\n",
    "        \n",
    "    return text_lst, edu_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_terms_indeed(df, terms):\n",
    "    for term in terms:\n",
    "        url = \"https://www.indeed.com/jobs?q=\" + term.replace(\" \", \"+\") + \"&fromage=1\"\n",
    "        myRequest = requests.get(url)\n",
    "        soup = str(BeautifulSoup(myRequest.text, \"html.parser\"))\n",
    "\n",
    "        title_match = 'rel=\"noopener nofollow\" target=\"_blank\" title=\"([^\"]+)'\n",
    "        titles = [x.replace(\"amp;\", \"\") for x in re.findall(title_match, soup)]\n",
    "\n",
    "        match_1 = r'<span class=\"company\">\\n([^<]+)'\n",
    "        match_2 = r'rel=\"noopener\" target=\"_blank\">\\n([^<]+)'\n",
    "\n",
    "        companies = [get_str(x).replace(\"amp;\", \"\") for x in re.findall(match_1 + '|' + match_2, soup)]\n",
    "\n",
    "        url_match = r'data-tn-element=\"jobTitle\" href=\"([^\"]+)' \n",
    "        urls = [\"https://www.indeed.com\" + x.replace(\"amp;\", \"\") for x in re.findall(url_match, soup)]\n",
    "\n",
    "        texts, educations = get_text_indeed(companies, titles, urls)\n",
    "        location_match = r'data-rc-loc=\"([^\"]+)'\n",
    "        locations = re.findall(location_match, soup)\n",
    "\n",
    "        new_df = pd.DataFrame()\n",
    "\n",
    "        new_df['Platform'] = [\"Indeed\"] * len(companies)\n",
    "        new_df['Search_Term'] = [term] * len(companies)\n",
    "        new_df['Title'] = titles\n",
    "        new_df['Company'] = companies\n",
    "        new_df['Location'] = locations\n",
    "        new_df['URL'] = urls\n",
    "        new_df['Text'] = texts\n",
    "        new_df['Education'] = educations\n",
    "        new_df['Date_Queried'] = [datetime.now().date()] * len(companies)\n",
    "\n",
    "        df = df.append(new_df, sort = False).drop_duplicates().reset_index(drop=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_tjfg(urls):\n",
    "    titles = [] \n",
    "    companies = []  \n",
    "    locations = []  \n",
    "    educations = []  \n",
    "    texts = [] \n",
    "    for url in urls:\n",
    "        education = []\n",
    "        myRequest = requests.get(url)\n",
    "        soup = str(BeautifulSoup(myRequest.text, \"html.parser\"))\n",
    "        paragraph_text = r'<p>(.*?)</p>'\n",
    "        list_text = r'<li>(.*?)</li>'\n",
    "        clean = re.compile('<.*?>')\n",
    "        text = \" \".join([re.sub(clean, '', get_str(x)).replace(\"amp;\", \"\") for x in re.findall(paragraph_text + \"|\" + list_text, soup)])\n",
    "        texts.append(text)\n",
    "        title_match = '<h1 itemprop=\"title\">(.*?)</h1>'\n",
    "        titles.append(re.findall(title_match, soup)[0])\n",
    "        loc_match = '<span itemprop=\"jobLocation\">(.*?)</span>'\n",
    "        locations.append(re.findall(loc_match, soup)[0])\n",
    "        company_match = '>(.*?)</a></span>'\n",
    "        companies.append(re.findall(company_match, soup)[0])\n",
    "        if len(re.findall(\"(?i) GED |High School\", text)) > 0:\n",
    "            education.append(\"High School\")\n",
    "        if len(re.findall(\" BS | BA | B.S. | B.A. |Bachelor\", text)) > 0:\n",
    "            education.append(\"Bachelor's\")\n",
    "        if len(re.findall(\" MS | M.S. |Master\", text)) > 0:\n",
    "            education.append(\"Master's\")\n",
    "        if len(re.findall(\"PhD | Ph.D. |Doctorate\", text)) > 0:\n",
    "            education.append(\"PhD\")\n",
    "        educations.append(\" \".join(education))\n",
    "    return titles, companies, locations, educations, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_terms_tjfg(df, terms):\n",
    "    for term in terms:\n",
    "        url = url = \"https://techjobsforgood.com/?q=\" + term\n",
    "        myRequest = requests.get(url)\n",
    "        soup = str(BeautifulSoup(myRequest.text, \"html.parser\"))\n",
    "        soup = re.sub(\"A-1\", \"\", soup)\n",
    "        \n",
    "        url_match = \"/jobs/(\\d+)\"\n",
    "        urls = list(set([\"http://techjobsforgood.com/jobs/\" + x + \"/\" for x in re.findall(url_match, soup)]))\n",
    "        \n",
    "        titles, companies, locations, educations, texts = get_info_tjfg(urls)\n",
    "\n",
    "        new_df = pd.DataFrame()\n",
    "\n",
    "        new_df['Platform'] = [\"TJFG\"] * len(companies)\n",
    "        new_df['Search_Term'] = [term] * len(companies)\n",
    "        new_df['Title'] = titles\n",
    "        new_df['Company'] = companies\n",
    "        new_df['Location'] = locations\n",
    "        new_df['URL'] = urls\n",
    "        new_df['Text'] = texts\n",
    "        new_df['Education'] = educations\n",
    "        new_df['Date_Queried'] = [datetime.now().date()] * len(companies)\n",
    "\n",
    "        df = df.append(new_df, sort = False).drop_duplicates().reset_index(drop=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = [\"Engineer\", \"Analyst\", \"Research\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New DataFrame code below\n",
    "#df = pd.DataFrame(columns = ['Platform','Search_Term','Title','Company','Location',\n",
    "#                             'URL','Education','Text','Date_Queried'])\n",
    "#start_point = 0\n",
    "\n",
    "df = pd.read_csv(\"ectj_postings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_terms_tjfg(df, search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_terms_indeed(df, search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['URL']).reset_index(drop=True)\n",
    "df = df.loc[df[\"Text\"].notna()].reset_index(drop=True)\n",
    "df = df.loc[df[\"Text\"] != \"\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_files(df[\"Company\"], df[\"Title\"], df[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Search_Term</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>URL</th>\n",
       "      <th>Education</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date_Queried</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Indeed</td>\n",
       "      <td>Research</td>\n",
       "      <td>Research Assistant l, 40 Hours, Days, BWH - Sl...</td>\n",
       "      <td>Brigham &amp; Women's Hospital(BWH)</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=b6948d92e43b1...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2020-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Indeed</td>\n",
       "      <td>Research</td>\n",
       "      <td>Assistant Research Scientist</td>\n",
       "      <td>New York University</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>https://www.indeed.com/company/Center-for-Lati...</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>To provide a full range of research related su...</td>\n",
       "      <td>2020-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Indeed</td>\n",
       "      <td>Research</td>\n",
       "      <td>Research Coordinator</td>\n",
       "      <td>Texas State University</td>\n",
       "      <td>Round Rock, TX</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=6835710be0e13...</td>\n",
       "      <td></td>\n",
       "      <td>This position is located on the Round Rock Cam...</td>\n",
       "      <td>2020-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Indeed</td>\n",
       "      <td>Research</td>\n",
       "      <td>Senior Research Associate (6610U) - Terner Cen...</td>\n",
       "      <td>University of California Berkeley</td>\n",
       "      <td>Berkeley, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=98b99853d96aa...</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Exceptional organizational, project management...</td>\n",
       "      <td>2020-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Indeed</td>\n",
       "      <td>Research</td>\n",
       "      <td>Epidemiologist II</td>\n",
       "      <td>City &amp; County of San Francisco</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=6533fc9170313...</td>\n",
       "      <td></td>\n",
       "      <td>2803 Epidemiologist II Department of Public He...</td>\n",
       "      <td>2020-09-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Platform Search_Term                                              Title  \\\n",
       "273   Indeed    Research  Research Assistant l, 40 Hours, Days, BWH - Sl...   \n",
       "274   Indeed    Research                       Assistant Research Scientist   \n",
       "275   Indeed    Research                               Research Coordinator   \n",
       "276   Indeed    Research  Senior Research Associate (6610U) - Terner Cen...   \n",
       "277   Indeed    Research                                  Epidemiologist II   \n",
       "\n",
       "                               Company           Location  \\\n",
       "273    Brigham & Women's Hospital(BWH)         Boston, MA   \n",
       "274                New York University       New York, NY   \n",
       "275             Texas State University     Round Rock, TX   \n",
       "276  University of California Berkeley       Berkeley, CA   \n",
       "277     City & County of San Francisco  San Francisco, CA   \n",
       "\n",
       "                                                   URL   Education  \\\n",
       "273  https://www.indeed.com/rc/clk?jk=b6948d92e43b1...               \n",
       "274  https://www.indeed.com/company/Center-for-Lati...  Bachelor's   \n",
       "275  https://www.indeed.com/rc/clk?jk=6835710be0e13...               \n",
       "276  https://www.indeed.com/rc/clk?jk=98b99853d96aa...  Bachelor's   \n",
       "277  https://www.indeed.com/rc/clk?jk=6533fc9170313...               \n",
       "\n",
       "                                                  Text Date_Queried  \n",
       "273                                                      2020-09-09  \n",
       "274  To provide a full range of research related su...   2020-09-09  \n",
       "275  This position is located on the Round Rock Cam...   2020-09-09  \n",
       "276  Exceptional organizational, project management...   2020-09-09  \n",
       "277  2803 Epidemiologist II Department of Public He...   2020-09-09  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ectj_postings.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
